import numpy as np
import pandas as pd
import statsmodels.api as sm

def backwardSelection(X, y, model_type="linear", elimination_criteria="aic", varchar_process="dummy_dropfirst", sl=0.05):
    """
    Backward Selection is a function, based on regression models, that returns significant features and selection iterations.\n
    Required Libraries: pandas, numpy, statmodels
    
    Parameters
    ----------
    X : Independent variables (Pandas DataFrame)\n
    y : Dependent variable (Pandas Series, Pandas DataFrame)\n
    model_type : 'linear' or 'logistic'\n
    elimination_criteria : 'aic', 'bic', 'r2', 'adjr2' or None\n
        'aic' refers Akaike information criterion\n
        'bic' refers Bayesian information criterion\n
        'r2' refers R-squared (Only works on linear model type)\n
        'adjr2' refers Adjusted R-squared (Only works on linear model type)\n
    varchar_process : 'drop', 'dummy' or 'dummy_dropfirst'\n
        'drop' drops varchar features\n
        'dummy' creates dummies for all levels of all varchars\n
        'dummy_dropfirst' creates dummies for all levels of all varchars, and drops first levels\n
    sl : Significance Level (default: 0.05)\n
    
    Returns
    -------
    columns(list), iteration_logs(str)\n\n
    Not Returns a Model
    
    Tested On
    ---------
    Python v3.11.7, Pandas v2.1.4, Numpy v1.26.4, StatsModels v0.14.1
    
    See Also
    --------
    https://en.wikipedia.org/wiki/Stepwise_regression    
    """
    X = __varcharProcessing__(X, varchar_process=varchar_process)
    return __backwardSelectionRaw__(X, y, model_type=model_type, elimination_criteria=elimination_criteria, sl=sl)

def __varcharProcessing__(X, varchar_process="dummy_dropfirst"):
    dtypes = X.dtypes
    if varchar_process == "drop":
        X = X.drop(columns=dtypes[dtypes == object].index.tolist())
        print("Character Variables (Dropped):", dtypes[dtypes == object].index.tolist())
    elif varchar_process == "dummy":
        X = pd.get_dummies(X, drop_first=False)
        print("Character Variables (Dummies Generated):", dtypes[dtypes == object].index.tolist())
    elif varchar_process == "dummy_dropfirst":
        X = pd.get_dummies(X, drop_first=True)
        print("Character Variables (Dummies Generated, First Dummies Dropped):", dtypes[dtypes == object].index.tolist())
    else:
        X = pd.get_dummies(X, drop_first=True)
        print("Character Variables (Dummies Generated, First Dummies Dropped):", dtypes[dtypes == object].index.tolist())

    X["intercept"] = 1
    cols = X.columns.tolist()
    cols = cols[-1:] + cols[:-1]
    X = X[cols]

    return X

def __backwardSelectionRaw__(X, y, model_type="linear", elimination_criteria="aic", sl=0.05):
    iterations_log = ""
    last_eliminated = ""
    cols = X.columns.tolist()

    def regressor(y, X, model_type=model_type):
        if model_type == "linear":
            regressor = sm.OLS(y, X).fit()
        elif model_type == "logistic":
            regressor = sm.Logit(y, X).fit()
        else:
            print("\nWrong Model Type : " + model_type + "\nLinear model type is selected.")
            model_type = "linear"
            regressor = sm.OLS(y, X).fit()
        return regressor

    for i in range(X.shape[1]):
        if i != 0:
            model = regressor(y, X)
            if elimination_criteria == "aic":
                criteria = model.aic
            elif elimination_criteria == "bic":
                criteria = model.bic
            elif elimination_criteria == "adjr2" and model_type == "linear":
                criteria = model.rsquared_adj
            elif elimination_criteria == "r2" and model_type == "linear":
                criteria = model.rsquared
            else:
                criteria = model.aic

            pvals = model.pvalues.drop("intercept")
            max_pval = pvals.max()

            if max_pval > sl:
                pval_index = pvals.idxmax()
                print("Eliminated:", pval_index)
                iterations_log += "\n\nEliminated: " + pval_index + "\n\n"
                del X[pval_index]
                last_eliminated = pval_index
            else:
                break
        else:
            model = regressor(y, X)
            iterations_log += "\n" + str(model.summary()) + "\nAIC: " + str(model.aic) + "\nBIC: " + str(
                model.bic) + "\n"
    print(str(model.summary()) + "\nAIC: " + str(model.aic) + "\nBIC: " + str(model.bic))
    print("Final Variables:", cols)
    iterations_log += "\n" + str(model.summary()) + "\nAIC: " + str(model.aic) + "\nBIC: " + str(model.bic) + "\n"
    return cols, iterations_log
